"""
YouTube Piano Music Analyzer
Downloads YouTube audio and converts to MIDI-like JSON using Spotify's basic-pitch.
åŒ…å«å°ˆæ¥­ç´šéŸ³ç¬¦æ¸…æ´—èˆ‡åŠ›åº¦æ›²ç·šå„ªåŒ–ã€‚
"""

import os
import json
import tempfile
import logging
import math
from pathlib import Path
from typing import Optional, Callable, List, Dict, Any, Tuple
from collections import defaultdict
import warnings

import yt_dlp

# è¨­å®šæ—¥èªŒ
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# æŠ‘åˆ¶ä¸å¿…è¦çš„è­¦å‘Š
warnings.filterwarnings('ignore', category=FutureWarning)
warnings.filterwarnings('ignore', category=UserWarning)


# ============================================
# å°ˆæ¥­ç´šéŸ³ç¬¦æ¸…æ´—èˆ‡å„ªåŒ–å‡½æ•¸
# ============================================

def apply_velocity_curve(velocity: int, curve_type: str = 'piano') -> int:
    """
    åŠ›åº¦æ›²ç·šé‡æ˜ å°„ - æ¨¡æ“¬çœŸå¯¦é‹¼ç´çš„ç‰©ç†ç‰¹æ€§
    
    AI çµ¦çš„åŠ›åº¦é€šå¸¸å¤ªå¹³å‡ï¼ˆé›†ä¸­åœ¨ 60-80 ç¯„åœï¼‰ï¼Œ
    é€™æœƒè®“å½ˆå¥è½èµ·ä¾†å¾ˆæ­»æ¿ã€‚é€é S-Curve æ˜ å°„å¯ä»¥ï¼š
    1. å¢å¼·è¼•æŸ”éŸ³ç¬¦çš„è¡¨ç¾åŠ›ï¼ˆæ›´è¼•ï¼‰
    2. å¼·èª¿é‡æ“ŠéŸ³ç¬¦çš„è¡æ“Šæ„Ÿï¼ˆæ›´å¼·ï¼‰
    3. ä¿æŒä¸­é–“åŠ›åº¦çš„è‡ªç„¶éæ¸¡
    
    Args:
        velocity: åŸå§‹åŠ›åº¦ (1-127)
        curve_type: æ›²ç·šé¡å‹ ('piano', 'linear', 'soft', 'hard')
    
    Returns:
        å„ªåŒ–å¾Œçš„åŠ›åº¦ (1-127)
    """
    # æ­£è¦åŒ–åˆ° 0-1
    v = max(0, min(127, velocity)) / 127.0
    
    if curve_type == 'piano':
        # S-Curve: å¢å¼·å‹•æ…‹å°æ¯”åº¦
        # ä½¿ç”¨ tanh å‡½æ•¸æ¨¡æ“¬é‹¼ç´è§¸æ„Ÿ
        # å°‡ä¸­å¿ƒé»ç¨å¾®ä¸‹ç§»ï¼Œè®“è¼•æŸ”çš„éƒ¨åˆ†æ›´æ˜é¡¯
        v_mapped = (math.tanh((v - 0.5) * 3) + 1) / 2
        # å¾®èª¿ï¼šä¿ç•™ä¸€äº›åŸå§‹åŠ›åº¦ç‰¹å¾µ
        v_mapped = v_mapped * 0.7 + v * 0.3
        
    elif curve_type == 'soft':
        # å°æ•¸æ›²ç·šï¼šæ›´æŸ”å’Œçš„å‹•æ…‹
        v_mapped = math.log1p(v * (math.e - 1)) / math.log(math.e)
        
    elif curve_type == 'hard':
        # æŒ‡æ•¸æ›²ç·šï¼šæ›´å¼·çƒˆçš„å‹•æ…‹å°æ¯”
        v_mapped = v ** 0.5
        
    else:  # linear
        v_mapped = v
    
    # è½‰å› 1-127 ç¯„åœ
    return max(1, min(127, int(v_mapped * 127)))


def refine_notes(
    raw_notes: List[Dict[str, Any]],
    min_gap: float = 0.05,
    max_duration: float = 3.0,
    apply_velocity_optimization: bool = True
) -> List[Dict[str, Any]]:
    """
    å°éŸ³ç¬¦é€²è¡Œå°ˆæ¥­ç´šé‚è¼¯æ¸…æ´—
    
    è§£æ±º AI èª¤åˆ¤ç”¢ç”Ÿçš„å•é¡Œï¼š
    1. ç¢éŸ³åˆä½µ (De-jittering)
    2. æœ€å¤§é•·åº¦é™åˆ¶ (Sustain Pedal Fix)
    3. åŠ›åº¦æ›²ç·šå„ªåŒ– (Velocity Mapping)
    4. å–®éŸ³è»Œé‚è¼¯æ ¡æ­£ (Monophonic Constraint)
    
    Args:
        raw_notes: åˆæ­¥éæ¿¾å¾Œçš„éŸ³ç¬¦åˆ—è¡¨
        min_gap: æœ€å°é–“éš”é–¾å€¼(ç§’)ï¼Œå°æ–¼æ­¤å€¼çš„é€£çºŒéŸ³ç¬¦æœƒè¢«åˆä½µ
        max_duration: æœ€å¤§éŸ³ç¬¦é•·åº¦(ç§’)ï¼Œè¶…éæ­¤å€¼æœƒè¢«æˆªæ–·ï¼ˆé˜²æ­¢è¸æ¿å»¶éŸ³å•é¡Œï¼‰
        apply_velocity_optimization: æ˜¯å¦æ‡‰ç”¨åŠ›åº¦æ›²ç·šå„ªåŒ–
    
    Returns:
        æ¸…æ´—å¾Œçš„éŸ³ç¬¦åˆ—è¡¨
    """
    if not raw_notes:
        return []
    
    # 1. æŒ‰éŸ³é«˜(pitch)åˆ†çµ„
    notes_by_pitch: Dict[int, List[Dict]] = defaultdict(list)
    for note in raw_notes:
        notes_by_pitch[note['pitch']].append(note)
    
    refined: List[Dict[str, Any]] = []
    merge_count = 0
    truncate_count = 0
    
    for pitch, pitch_group in notes_by_pitch.items():
        # æŒ‰é–‹å§‹æ™‚é–“æ’åº
        pitch_group.sort(key=lambda x: x['start_time'])
        
        if not pitch_group:
            continue
        
        # åˆå§‹åŒ–ç•¶å‰éŸ³ç¬¦
        current = pitch_group[0].copy()
        
        for i in range(1, len(pitch_group)):
            next_note = pitch_group[i]
            
            # è¨ˆç®—é–“éš”ï¼šä¸‹ä¸€å€‹é–‹å§‹æ™‚é–“ - ç•¶å‰çµæŸæ™‚é–“
            current_end = current['start_time'] + current['duration']
            gap = next_note['start_time'] - current_end
            
            if gap < min_gap:
                # åˆä½µéŸ³ç¬¦ï¼šå»¶é•·ç•¶å‰éŸ³ç¬¦
                merge_count += 1
                next_end = next_note['start_time'] + next_note['duration']
                new_end = max(current_end, next_end)
                current['duration'] = round(new_end - current['start_time'], 3)
                # åŠ›åº¦å–æœ€å¤§å€¼ï¼Œæ¨¡æ“¬é‡æ“Šæ„Ÿ
                current['velocity'] = max(current['velocity'], next_note['velocity'])
            else:
                # ä¿å­˜ç•¶å‰éŸ³ç¬¦ï¼Œé–‹å§‹æ–°éŸ³ç¬¦
                refined.append(current)
                current = next_note.copy()
        
        # ä¿å­˜æœ€å¾Œä¸€å€‹éŸ³ç¬¦
        refined.append(current)
    
    # 2. æ‡‰ç”¨æœ€å¤§é•·åº¦é™åˆ¶ï¼ˆè§£æ±ºè¸æ¿å»¶éŸ³å•é¡Œï¼‰
    for note in refined:
        if note['duration'] > max_duration:
            note['duration'] = max_duration
            truncate_count += 1
    
    # 3. æ‡‰ç”¨åŠ›åº¦æ›²ç·šå„ªåŒ–
    if apply_velocity_optimization:
        for note in refined:
            note['velocity'] = apply_velocity_curve(note['velocity'], 'piano')
    
    # 4. æŒ‰é–‹å§‹æ™‚é–“æ’åº
    refined.sort(key=lambda x: x['start_time'])
    
    if merge_count > 0:
        logger.info(f"ğŸ“[Refine] åˆä½µäº† {merge_count} å€‹ç¢éŸ³")
    if truncate_count > 0:
        logger.info(f"ğŸ“[Refine] æˆªæ–·äº† {truncate_count} å€‹éé•·éŸ³ç¬¦ (max={max_duration}s)")
    
    return refined


def preprocess_audio_with_ffmpeg(input_path: Path, output_dir: Path) -> Path:
    """
    ä½¿ç”¨ FFmpeg å°éŸ³è¨Šé€²è¡Œé è™•ç†ï¼Œæå‡ AI åˆ†ææº–ç¢ºåº¦
    
    è™•ç†å…§å®¹ï¼š
    1. é«˜é€šæ¿¾æ³¢ (High-pass Filter): ç§»é™¤ 30Hz ä»¥ä¸‹çš„æ¥µä½é »å™ªéŸ³
    2. å£“ç¸®å™¨ (Compressor): å¹³è¡¡å‹•æ…‹ç¯„åœï¼Œè®“ AI æ›´å®¹æ˜“è­˜åˆ¥è¼•æŸ”éŸ³ç¬¦
    3. æ­£è¦åŒ– (Normalize): çµ±ä¸€éŸ³é‡æ°´å¹³
    
    Args:
        input_path: åŸå§‹éŸ³è¨Šè·¯å¾‘
        output_dir: è¼¸å‡ºç›®éŒ„
    
    Returns:
        é è™•ç†å¾Œçš„éŸ³è¨Šè·¯å¾‘
    """
    import subprocess
    import shutil
    
    # æª¢æŸ¥ FFmpeg æ˜¯å¦å¯ç”¨
    if not shutil.which('ffmpeg'):
        logger.warning("ğŸ“[Preprocess] FFmpeg æœªå®‰è£ï¼Œè·³éé è™•ç†")
        return input_path
    
    output_path = output_dir / f"{input_path.stem}_processed.wav"
    
    # FFmpeg æ¿¾æ³¢éˆï¼š
    # - highpass: 30Hz é«˜é€šæ¿¾æ³¢ï¼Œç§»é™¤æ¥µä½é »å™ªéŸ³
    # - compand: å£“ç¸®å™¨ï¼Œå¹³è¡¡å‹•æ…‹ç¯„åœ
    # - loudnorm: éŸ³é‡æ­£è¦åŒ–
    filter_chain = (
        "highpass=f=30,"
        "compand=attacks=0.1:decays=0.3:points=-80/-80|-30/-15|0/0:soft-knee=6,"
        "loudnorm=I=-16:TP=-1.5:LRA=11"
    )
    
    cmd = [
        'ffmpeg', '-y', '-i', str(input_path),
        '-af', filter_chain,
        '-ar', '44100',  # ç¢ºä¿æ¡æ¨£ç‡
        '-ac', '1',       # è½‰æ›ç‚ºå–®è²é“ï¼ˆæ›´ä¹¾æ·¨ï¼‰
        str(output_path)
    ]
    
    try:
        result = subprocess.run(
            cmd,
            capture_output=True,
            text=True,
            timeout=60
        )
        
        if result.returncode == 0 and output_path.exists():
            logger.info(f"ğŸ“[Preprocess] éŸ³è¨Šé è™•ç†å®Œæˆ: {output_path.name}")
            return output_path
        else:
            logger.warning(f"ğŸ“[Preprocess] FFmpeg è™•ç†å¤±æ•—: {result.stderr[:200]}")
            return input_path
            
    except subprocess.TimeoutExpired:
        logger.warning("ğŸ“[Preprocess] FFmpeg è™•ç†è¶…æ™‚")
        return input_path
    except Exception as e:
        logger.warning(f"ğŸ“[Preprocess] é è™•ç†å¤±æ•—: {e}")
        return input_path


def adaptive_filter_notes(
    notes: List[Dict[str, Any]],
    window_size: float = 0.1,
    chord_threshold: int = 4
) -> List[Dict[str, Any]]:
    """
    è‡ªé©æ‡‰é–€æª»éæ¿¾ - æ ¹æ“šå’Œå¼¦å¯†åº¦å‹•æ…‹èª¿æ•´éæ¿¾åƒæ•¸
    
    ç•¶åµæ¸¬åˆ°å’Œå¼¦ï¼ˆçŸ­æ™‚é–“å…§å¤§é‡éŸ³ç¬¦ï¼‰æ™‚ï¼Œé™ä½åŠ›åº¦é–€æª»
    ä»¥æ•æ‰è¢«å¤§è²é®è”½çš„ç´°å¾®éŸ³ç¬¦ã€‚
    
    Args:
        notes: éŸ³ç¬¦åˆ—è¡¨
        window_size: æ™‚é–“çª—å£å¤§å°(ç§’)
        chord_threshold: åˆ¤å®šç‚ºå’Œå¼¦çš„æœ€å°éŸ³ç¬¦æ•¸
    
    Returns:
        éæ¿¾å¾Œçš„éŸ³ç¬¦åˆ—è¡¨
    """
    if not notes:
        return []
    
    # æŒ‰é–‹å§‹æ™‚é–“æ’åº
    sorted_notes = sorted(notes, key=lambda x: x['start_time'])
    
    # åˆ†ææ¯å€‹æ™‚é–“çª—å£çš„éŸ³ç¬¦å¯†åº¦
    result = []
    i = 0
    
    while i < len(sorted_notes):
        current_time = sorted_notes[i]['start_time']
        window_end = current_time + window_size
        
        # æ‰¾å‡ºé€™å€‹çª—å£å…§çš„æ‰€æœ‰éŸ³ç¬¦
        window_notes = []
        j = i
        while j < len(sorted_notes) and sorted_notes[j]['start_time'] < window_end:
            window_notes.append(sorted_notes[j])
            j += 1
        
        note_count = len(window_notes)
        
        if note_count >= chord_threshold:
            # å’Œå¼¦å€å¡Šï¼šé™ä½åŠ›åº¦é–€æª»ä»¥æ•æ‰ç´°ç¯€
            local_min_velocity = 8
        elif note_count >= 2:
            # é›™éŸ³/ä¸‰éŸ³ï¼šä¸­ç­‰é–€æª»
            local_min_velocity = 12
        else:
            # å–®éŸ³æ—‹å¾‹ï¼šæé«˜é–€æª»é¿å…é›œè¨Š
            local_min_velocity = 18
        
        # æ‡‰ç”¨éæ¿¾
        for note in window_notes:
            if note['velocity'] >= local_min_velocity:
                if note not in result:
                    result.append(note)
        
        i = j if j > i else i + 1
    
    return result


def filter_harmonics(
    notes: List[Dict[str, Any]],
    harmonic_threshold: float = 0.4
) -> List[Dict[str, Any]]:
    """
    æ³›éŸ³éæ¿¾ - ç§»é™¤å¯èƒ½æ˜¯æ³›éŸ³çš„å‡éŸ³ç¬¦
    
    å¦‚æœåœ¨åŒä¸€æ™‚é–“é»åµæ¸¬åˆ°ä½éŸ³ (C3) å’Œå…¶å…«åº¦éŸ³ (C4)ï¼Œ
    ä¸”é«˜éŸ³åŠ›åº¦æ˜é¡¯è¼ƒå¼±ï¼Œå‰‡å¾ˆå¯èƒ½æ˜¯æ³›éŸ³è€ŒéçœŸå¯¦å½ˆå¥ã€‚
    
    Args:
        notes: éŸ³ç¬¦åˆ—è¡¨
        harmonic_threshold: æ³›éŸ³åˆ¤å®šé–¾å€¼ (0-1)
    
    Returns:
        éæ¿¾å¾Œçš„éŸ³ç¬¦åˆ—è¡¨
    """
    if not notes:
        return []
    
    # æŒ‰é–‹å§‹æ™‚é–“åˆ†çµ„ï¼ˆå…è¨± 20ms èª¤å·®ï¼‰
    TIME_TOLERANCE = 0.02
    sorted_notes = sorted(notes, key=lambda x: x['start_time'])
    
    # æ¨™è¨˜è¦ç§»é™¤çš„éŸ³ç¬¦
    to_remove = set()
    
    for i, note in enumerate(sorted_notes):
        base_pitch = note['pitch']
        base_velocity = note['velocity']
        base_time = note['start_time']
        
        # æª¢æŸ¥åŒæ™‚é–“æ®µçš„å…¶ä»–éŸ³ç¬¦
        for j, other in enumerate(sorted_notes):
            if i == j or j in to_remove:
                continue
            
            # æ™‚é–“æ˜¯å¦æ¥è¿‘
            if abs(other['start_time'] - base_time) > TIME_TOLERANCE:
                continue
            
            other_pitch = other['pitch']
            other_velocity = other['velocity']
            
            # æª¢æŸ¥æ˜¯å¦ç‚ºæ³›éŸ³é—œä¿‚ (å…«åº¦ = 12 å€‹åŠéŸ³)
            pitch_diff = other_pitch - base_pitch
            
            # å¸¸è¦‹æ³›éŸ³é—œä¿‚ï¼šå…«åº¦(12), äº”åº¦(7), é›™å…«åº¦(24)
            if pitch_diff in [12, 24, 7, 19]:
                # å¦‚æœé«˜éŸ³åŠ›åº¦æ˜é¡¯è¼ƒå¼±ï¼Œå¯èƒ½æ˜¯æ³›éŸ³
                velocity_ratio = other_velocity / max(base_velocity, 1)
                
                if velocity_ratio < harmonic_threshold:
                    to_remove.add(j)
                    logger.debug(f"ğŸ“[Harmonic] ç§»é™¤å¯èƒ½æ³›éŸ³: {other_pitch} (åŸºéŸ³ {base_pitch}, åŠ›åº¦æ¯” {velocity_ratio:.2f})")
    
    result = [note for i, note in enumerate(sorted_notes) if i not in to_remove]
    
    if to_remove:
        logger.info(f"ğŸ“[Harmonic] ç§»é™¤äº† {len(to_remove)} å€‹å¯èƒ½çš„æ³›éŸ³")
    
    return result


def download_audio(
    youtube_url: str,
    output_dir: Path,
    progress_callback: Optional[Callable[[str, float], None]] = None
) -> Tuple[Path, str]:
    """
    ä½¿ç”¨ yt-dlp ä¸‹è¼‰ YouTube éŸ³è¨Šç‚º MP3 æ ¼å¼
    
    Args:
        youtube_url: YouTube ç¶²å€
        output_dir: è¼¸å‡ºç›®éŒ„
        progress_callback: é€²åº¦å›èª¿ (stage, percent)
    
    Returns:
        (éŸ³è¨Šæª”æ¡ˆè·¯å¾‘, å½±ç‰‡æ¨™é¡Œ)
    """
    output_dir.mkdir(parents=True, exist_ok=True)
    output_template = str(output_dir / "%(id)s.%(ext)s")
    
    def progress_hook(d):
        if d['status'] == 'downloading':
            if progress_callback:
                # è§£æé€²åº¦ç™¾åˆ†æ¯”
                percent = d.get('_percent_str', '0%').strip().replace('%', '')
                try:
                    progress_callback('downloading', float(percent))
                except ValueError:
                    pass
        elif d['status'] == 'finished':
            if progress_callback:
                progress_callback('downloading', 100)
    
    ydl_opts = {
        'format': 'bestaudio/best',
        'outtmpl': output_template,
        'postprocessors': [{
            'key': 'FFmpegExtractAudio',
            'preferredcodec': 'mp3',
            'preferredquality': '320',  # æå‡è‡³ 320kbps ä»¥ç²å¾—æ›´å¥½çš„é«˜é »è§£æ
        }],
        'progress_hooks': [progress_hook],
        'quiet': True,
        'no_warnings': True,
        # é¿å…ä¸‹è¼‰éé•·çš„å½±ç‰‡ (é™åˆ¶ 10 åˆ†é˜)
        'match_filter': yt_dlp.utils.match_filter_func("duration < 600"),
    }
    
    try:
        with yt_dlp.YoutubeDL(ydl_opts) as ydl:
            info = ydl.extract_info(youtube_url, download=True)
            video_id = info.get('id', 'audio')
            video_title = info.get('title', 'Unknown')
            
            # æ‰¾åˆ°ä¸‹è¼‰çš„ MP3 æª”æ¡ˆ
            audio_path = output_dir / f"{video_id}.mp3"
            
            if not audio_path.exists():
                raise FileNotFoundError(f"ä¸‹è¼‰å®Œæˆä½†æ‰¾ä¸åˆ°éŸ³è¨Šæª”æ¡ˆ: {audio_path}")
            
            logger.info(f"ğŸ“[Analyzer] éŸ³è¨Šä¸‹è¼‰å®Œæˆ: {video_title}")
            return audio_path, video_title
            
    except yt_dlp.utils.DownloadError as e:
        logger.error(f"ğŸ“[Analyzer] ä¸‹è¼‰å¤±æ•—: {e}")
        raise RuntimeError(f"YouTube ä¸‹è¼‰å¤±æ•—: {str(e)}")


def analyze_audio_with_basic_pitch(
    audio_path: Path,
    output_dir: Path,
    progress_callback: Optional[Callable[[str, float], None]] = None,
    enable_preprocessing: bool = True,
    chord_mode: bool = True
) -> Path:
    """
    ä½¿ç”¨ Spotify basic-pitch é€²è¡ŒéŸ³è¨Šåˆ†æä¸¦è½‰æ›ç‚º notes.json
    
    basic-pitch æ”¯æ´å¤šéŸ³è»Œï¼ˆå’Œå¼¦ï¼‰æª¢æ¸¬ï¼Œæ•ˆæœé å„ªæ–¼å–®éŸ³æª¢æ¸¬å™¨ã€‚
    
    Args:
        audio_path: MP3 éŸ³è¨Šè·¯å¾‘
        output_dir: JSON è¼¸å‡ºç›®éŒ„
        progress_callback: é€²åº¦å›èª¿
        enable_preprocessing: æ˜¯å¦å•Ÿç”¨ FFmpeg é è™•ç†
        chord_mode: æ˜¯å¦å•Ÿç”¨å’Œå¼¦æ¨¡å¼ï¼ˆé™ä½ onset/frame é–¾å€¼ï¼‰
    
    Returns:
        notes.json æª”æ¡ˆè·¯å¾‘
    """
    # å»¶é²å°å…¥ä»¥åŠ å¿«å•Ÿå‹•é€Ÿåº¦
    from basic_pitch.inference import predict
    from basic_pitch import ICASSP_2022_MODEL_PATH
    
    if progress_callback:
        progress_callback('analyzing', 5)
    
    # ============================================
    # éšæ®µ 1: FFmpeg éŸ³è¨Šé è™•ç† (é¸æ“‡æ€§)
    # ============================================
    processed_audio = audio_path
    if enable_preprocessing:
        logger.info(f"ğŸ“[Analyzer] é–‹å§‹éŸ³è¨Šé è™•ç†...")
        processed_audio = preprocess_audio_with_ffmpeg(audio_path, output_dir)
        
    if progress_callback:
        progress_callback('analyzing', 15)
    
    logger.info(f"ğŸ“[Analyzer] ä½¿ç”¨ basic-pitch åˆ†æ: {processed_audio}")
    
    try:
        # ============================================
        # éšæ®µ 2: èª¿æ•´ basic-pitch åƒæ•¸
        # ============================================
        # chord_mode: é™ä½é–¾å€¼ä»¥æ•æ‰æ›´å¤šå’Œå¼¦ç´°ç¯€
        if chord_mode:
            onset_thresh = 0.4    # é è¨­ ~0.5, é™ä½ä»¥æ•æ‰å’Œå¼¦
            frame_thresh = 0.25   # é è¨­ ~0.3, é™ä½è®“é•·éŸ³ä¸æ˜“æ–·æ‰
            min_note_len = 50     # æœ€å°éŸ³ç¬¦é•·åº¦ (ms)
        else:
            onset_thresh = 0.5
            frame_thresh = 0.3
            min_note_len = 80
        
        logger.info(f"ğŸ“[Analyzer] å’Œå¼¦æ¨¡å¼: {chord_mode}, onset={onset_thresh}, frame={frame_thresh}")
        
        # ä½¿ç”¨ predict å‡½æ•¸ç²å–åŸå§‹æ•¸æ“š
        model_output, midi_data, note_events = predict(
            str(processed_audio),
            model_or_model_path=ICASSP_2022_MODEL_PATH,
            onset_threshold=onset_thresh,
            frame_threshold=frame_thresh,
            minimum_note_length=min_note_len,
        )
        
        if progress_callback:
            progress_callback('analyzing', 50)
        
        # ============================================
        # éšæ®µ 3: åŸºç¤éæ¿¾ (ç¯„åœ + æ™‚é•· + åŠ›åº¦)
        # ============================================
        MIN_DURATION = 0.04    # æŠ¼ä½è‡³ 40ms (å’Œå¼¦æ¨¡å¼)
        MIN_VELOCITY = 10      # æŠ¼ä½ä»¥æ•æ‰è¢«é®è”½çš„éŸ³ç¬¦
        MERGE_THRESHOLD = 0.03 # åŒä¸€éŸ³é«˜åœ¨ 30ms å…§é‡è¤‡è§¸ç™¼è¦–ç‚ºé‡ç–Š
        
        # å°‡ note_events è½‰æ›ç‚ºæˆ‘å€‘éœ€è¦çš„ JSON æ ¼å¼
        # note_events æ˜¯ (start_time_s, end_time_s, pitch_midi, velocity, [pitch_bends])
        raw_notes: List[Dict[str, Any]] = []
        
        for note in note_events:
            start_time = float(note[0])
            end_time = float(note[1])
            pitch = int(note[2])  # MIDI pitch (0-127, 60 = Middle C)
            velocity = int(note[3] * 127)  # æ­£è¦åŒ–åˆ° 0-127
            duration = end_time - start_time
            
            # éæ¿¾ 1: é‹¼ç´ç¯„åœ (A0=21 åˆ° C8=108)
            if pitch < 21 or pitch > 108:
                continue
            
            # éæ¿¾ 2: æœ€å°æ™‚é•· (å»é™¤ç¢éŸ³é›œè¨Š)
            if duration < MIN_DURATION:
                continue
            
            # éæ¿¾ 3: æœ€å°åŠ›åº¦ (å»é™¤èƒŒæ™¯é›œè¨Š)
            if velocity < MIN_VELOCITY:
                continue
            
            raw_notes.append({
                "pitch": pitch,
                "start_time": round(start_time, 3),
                "end_time": round(end_time, 3),
                "duration": round(duration, 3),
                "velocity": min(127, max(1, velocity))
            })
        
        if progress_callback:
            progress_callback('analyzing', 60)
        
        # ============================================
        # éšæ®µ 4: è‡ªé©æ‡‰é–€æª»éæ¿¾ (å’Œå¼¦æ¨¡å¼)
        # ============================================
        if chord_mode:
            raw_notes = adaptive_filter_notes(
                raw_notes,
                window_size=0.1,
                chord_threshold=4
            )
        
        if progress_callback:
            progress_callback('analyzing', 70)
        
        # ============================================
        # éšæ®µ 5: æ³›éŸ³éæ¿¾
        # ============================================
        raw_notes = filter_harmonics(raw_notes, harmonic_threshold=0.35)
        
        if progress_callback:
            progress_callback('analyzing', 75)
        
        # ============================================
        # éšæ®µ 6: å°ˆæ¥­ç´šéŸ³ç¬¦æ¸…æ´— (ç¢éŸ³åˆä½µ + åŠ›åº¦æ›²ç·š)
        notes_json = refine_notes(
            raw_notes,
            min_gap=MERGE_THRESHOLD,
            apply_velocity_optimization=True
        )
        
        if progress_callback:
            progress_callback('analyzing', 85)
        
        # è¨ˆç®—ç¸½æ™‚é•·
        total_duration = max(n['start_time'] + n['duration'] for n in notes_json) if notes_json else 0
        
        # çµ±è¨ˆéæ¿¾ä¿¡æ¯
        original_count = len(note_events)
        filtered_count = len(notes_json)
        filter_rate = ((original_count - filtered_count) / original_count * 100) if original_count > 0 else 0
        
        logger.info(f"ğŸ“[Analyzer] éæ¿¾çµ±è¨ˆ: åŸå§‹ {original_count} â†’ éæ¿¾å¾Œ {filtered_count} ({filter_rate:.1f}% è¢«éæ¿¾)")
        
        # è¼¸å‡º JSON
        output_path = output_dir / "notes.json"
        output_data = {
            "metadata": {
                "total_duration": round(total_duration, 3),
                "note_count": len(notes_json),
                "source": str(audio_path.name),
                "analysis_method": "Spotify basic-pitch (ICASSP 2022) + Pro Pipeline",
                "processing_pipeline": {
                    "stage_1_ffmpeg_preprocessing": enable_preprocessing,
                    "stage_2_chord_mode": chord_mode,
                    "stage_3_basic_filter": True,
                    "stage_4_adaptive_threshold": chord_mode,
                    "stage_5_harmonic_filter": True,
                    "stage_6_velocity_curve": True
                },
                "parameters": {
                    "onset_threshold": onset_thresh,
                    "frame_threshold": frame_thresh,
                    "min_note_length_ms": min_note_len,
                    "min_duration_ms": MIN_DURATION * 1000,
                    "min_velocity": MIN_VELOCITY,
                    "merge_threshold_ms": MERGE_THRESHOLD * 1000
                },
                "statistics": {
                    "original_count": original_count,
                    "final_count": filtered_count,
                    "filter_rate_percent": round(filter_rate, 1)
                }
            },
            "notes": notes_json
        }
        
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(output_data, f, ensure_ascii=False, indent=2)
        
        if progress_callback:
            progress_callback('analyzing', 100)
        
        logger.info(f"ğŸ“[Analyzer] basic-pitch åˆ†æå®Œæˆ: {len(notes_json)} å€‹éŸ³ç¬¦, ç¸½æ™‚é•· {total_duration:.2f}s")
        return output_path
        
    except Exception as e:
        logger.error(f"ğŸ“[Analyzer] basic-pitch åˆ†æå¤±æ•—: {e}")
        raise RuntimeError(f"éŸ³è¨Šåˆ†æå¤±æ•—: {str(e)}")


def process_youtube(
    youtube_url: str,
    output_dir: Path,
    progress_callback: Optional[Callable[[str, float], None]] = None
) -> Dict[str, Any]:
    """
    å®Œæ•´æµç¨‹ï¼šä¸‹è¼‰ YouTube éŸ³è¨Šä¸¦åˆ†æç‚º JSON
    
    Args:
        youtube_url: YouTube ç¶²å€
        output_dir: è¼¸å‡ºç›®éŒ„
        progress_callback: é€²åº¦å›èª¿
    
    Returns:
        åŒ…å«åˆ†æçµæœçš„å­—å…¸
    """
    output_dir = Path(output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # éšæ®µ 1: ä¸‹è¼‰éŸ³è¨Š
    audio_path, video_title = download_audio(youtube_url, output_dir, progress_callback)
    
    # éšæ®µ 2: åˆ†æéŸ³è¨Š (ä½¿ç”¨ basic-pitch)
    json_path = analyze_audio_with_basic_pitch(audio_path, output_dir, progress_callback)
    
    # è®€å–ç”Ÿæˆçš„ JSON
    with open(json_path, 'r', encoding='utf-8') as f:
        result = json.load(f)
    
    result['metadata']['title'] = video_title
    result['metadata']['audio_file'] = str(audio_path.name)
    
    # é‡æ–°ä¿å­˜å¸¶æ¨™é¡Œçš„ç‰ˆæœ¬
    with open(json_path, 'w', encoding='utf-8') as f:
        json.dump(result, f, ensure_ascii=False, indent=2)
    
    return result


# CLI æ¸¬è©¦å…¥å£
if __name__ == "__main__":
    import sys
    
    if len(sys.argv) < 2:
        print("ç”¨æ³•: python analyzer.py <YouTube URL>")
        sys.exit(1)
    
    url = sys.argv[1]
    output = Path("./output")
    
    def print_progress(stage, percent):
        print(f"[{stage}] {percent:.1f}%")
    
    try:
        result = process_youtube(url, output, print_progress)
        print(f"\nâœ… åˆ†æå®Œæˆ!")
        print(f"   æ¨™é¡Œ: {result['metadata'].get('title', 'N/A')}")
        print(f"   éŸ³ç¬¦æ•¸: {result['metadata']['note_count']}")
        print(f"   ç¸½æ™‚é•·: {result['metadata']['total_duration']:.2f} ç§’")
    except Exception as e:
        print(f"\nâŒ å¤±æ•—: {e}")
        sys.exit(1)
